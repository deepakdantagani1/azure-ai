/**
 * use following tools to deploy the model
 * ==> Azure AI Studio 
 * ==> Azure CLI || 
 * ==> REST API to deploy a base model.
 */

/**
 * types of model 
 * ==> GPT chat completion based on the prompt (completion and chat completion)
 * ==>  Embeddings, 
 * ==> DALL-E 
 */

/**
 * limitations of the model
 * ==> The model is limited to 5000 tokens per request
 */

/**
 * OpenAI REST API (YOUR_ENDPOINT_NAME, YOUR_API_KEY, YOUR_DEPLOYMENT_NAME)
 * other parameters include: temperature, max_tokens, top_p, frequency_penalty, presence_penalty, stop, and logprobs
 */

/**
 * REST API or SDK to access the model
 */

/**
 * Prompts
 * ==> tags
 * ==> primary
 * ==> supporting
 * ==> grounding content
 * ==> clues
 * ==> output composition
 * ==> Conversation history
 * ==> Chain of thought
 * ==> Break down a complex task
 * ==> Few shot learning
 */

/**
 * Use the Azure OpenAI REST API to consume DALL-E models
 * 
 * The request must contain the following parameters in a JSON body:
 * ==> prompt: The text prompt to generate an image from
 * ==> n: The number of images to generate
 * ==> size: The size of the image to generate
 * ==> quality: The quality of the image to generate 
 * ==> style: (natural or vivid). Defaults to vivid.
 */

/**
 * Azure OpenAI and Retrieval Augmented Generation (RAG)
 * example: RAG in Legal Document Automation
 */

/**
 * Understand Retrieval Augmented Generation
 * 
 * Once data is in a AI Search index, Azure OpenAI on your data goes through the following steps:
 * ==> Receive user prompt
 * ==> Determine relevant content and intent of the prompt.
 * ==> Query the search index with that content and intent.
 * ==> Insert search result chunk into the Azure OpenAI prompt, along with system message and user prompt.
 * ==> Send entire prompt to Azure OpenAI.
 * ==> Return response and data reference (if any) to the user.
 * 
 */

/**
 * Fine-tuning vs. RAG
 * 
 * Fine-tuning is a technique used to create a custom model by training an existing foundational model such as 
 * gpt-35-turbo with a dataset of additional training data. Fine-tuning can result in higher quality requests than prompt engineering 
 * alone, customize the model on examples larger than can fit in a prompt, and allow the user to provide fewer examples to get the 
 * same high quality response. However, the process for fine-tuning is both costly and time intensive, and should only be used for 
 * use cases where it's necessary.

RAG with Azure OpenAI on your data still uses the stateless API to connect to the model, which removes 
the requirement of training a custom model with your data and simplifies the interaction with the AI model. AI Search first finds the 
useful information to answer the prompt, adds that to the prompt as grounding data, and Azure OpenAI forms the response based on 
that information.
 *
 */

/**
 * Semantic Search Fits into RAG
 * Semantic search is a type of search technology that understands the meaning behind the words in a query, 
 * rather than just matching keywords. Unlike traditional search engines that rely on exact word matches, semantic search 
 * focuses on the intent or context of the search, so it can deliver more relevant results.
 */



/**
 * tt defines a four stage process to develop and implement a plan for responsible AI when using generative models. 
 * The four stages in the process are:
 * 
 * ==> Identify potential harms that are relevant to your planned solution.
 * ==> Measure the presence of these harms in the outputs generated by your solution.
 * ==> Mitigate the harms at multiple layers in your solution to minimize their presence and impact, 
 * and ensure transparent communication about potential risks to users.
 * ==> Operate the solution responsibly by defining and following a deployment and operational readiness plan.
 */

/**
 * Mitigate potential harms techniques can be applied at each of four layers
 * 
 * ==> Model
 * ==> Safety System
 * ==> Metaprompt and grounding
 * ==> User experience
 * 
 */